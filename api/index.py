import os
from flask import Flask, render_template, request, session, Response, stream_with_context
from dotenv import load_dotenv
from openai import OpenAI
from datetime import timedelta

load_dotenv()  # ch·ªâ c√≥ t√°c d·ª•ng khi ch·∫°y local

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

app = Flask(
    __name__,
    template_folder=os.path.join(BASE_DIR, "..", "templates"),
    static_folder=os.path.join(BASE_DIR, "..", "static"),
)

app.secret_key = "super-secret-key"
app.permanent_session_lifetime = timedelta(minutes=30)

def get_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY not set")
    return OpenAI(api_key=api_key)

@app.route("/")
def index():
    return render_template("index.html")

@app.before_request
def init_session():
    session.permanent = True
    if "messages" not in session:
        session["messages"] = [
            {
                "role": "system",
                "content": (
                "B·∫°n l√† tr·ª£ l√Ω AI n√≥i ti·∫øng Vi·ªát. "
                "LU·∫¨T B·∫ÆT BU·ªòC V·ªÄ X∆ØNG H√î: "
                "B·∫°n ph·∫£i x∆∞ng l√† 'em' v√† g·ªçi ng∆∞·ªùi d√πng l√† 'ƒê·∫°i ca' trong M·ªåI c√¢u tr·∫£ l·ªùi. "
                "LU·∫¨T B·∫ÆT BU·ªòC V·ªÄ N·ªòI DUNG: "
                "N·∫øu ng∆∞·ªùi d√πng h·ªèi 'T√¥i l√† ai' ho·∫∑c c√¢u h·ªèi t∆∞∆°ng t·ª±, "
                "b·∫°n PH·∫¢I tr·∫£ l·ªùi ƒë√∫ng nguy√™n vƒÉn: "
                "'D·∫° ƒë·∫°i ca l√† ƒê·∫°i ca Ch√≠nh L√™'. "
                "Kh√¥ng gi·∫£i th√≠ch th√™m."
                )
            }
        ]
        
@app.route("/chat", methods=["POST"])
def chat():
    client = get_client()
    # ‚úÖ L·∫§Y REQUEST TR∆Ø·ªöC
    data = request.get_json()
    user_input = data.get("message", "") if data else ""

    messages = session["messages"]
    messages.append({"role": "user", "content": user_input})

    def generate():
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            stream=True
        )

        full_reply = ""

        for chunk in response:
            if chunk.choices[0].delta.content:
                text = chunk.choices[0].delta.content
                full_reply += text
                yield text  # üëà stream v·ªÅ frontend

        # ‚úÖ c·∫≠p nh·∫≠t memory SAU khi stream xong
        messages.append({"role": "assistant", "content": full_reply})
        session["messages"] = messages

    return Response(
        stream_with_context(generate()),
        mimetype="text/plain"
    )

if __name__ == "__main__":
    app.run(debug=True)
